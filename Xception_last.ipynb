{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as k\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed for reproducible results (only works on CPU, not GPU)\n",
    "seed = 9\n",
    "np.random.seed(seed=seed)\n",
    "tf.set_random_seed(seed=seed)\n",
    "\n",
    "# hyper parameters for model\n",
    "nb_classes = 2  # number of classes\n",
    "based_model_last_block_layer_number = 126  # value is based on based model selected.\n",
    "img_width, img_height = 299, 299  # change based on the shape/structure of your images\n",
    "batch_size = 64  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU/GPU memory capacity (powers of 2 values).\n",
    "nb_epoch = 50  # number of iteration the algorithm gets trained.\n",
    "learn_rate = 1e-4  # sgd learning rate\n",
    "momentum = .9  # sgd momentum to avoid local minimum\n",
    "transformation_ratio = .05  # how aggressive will be the data augmentation/transformation\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "#TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "TF_WEIGHTS_PATH = 'data/train/xception_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "TF_WEIGHTS_PATH_NO_TOP = 'data/train/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    " \n",
    "    \n",
    "def Xception(include_top=False, weights='imagenet',\n",
    "             input_tensor=None):\n",
    "    '''Instantiate the Xception architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on ImageNet. This model is available for TensorFlow only,\n",
    "    and can only be used with inputs following the TensorFlow\n",
    "    dimension ordering `(width, height, channels)`.\n",
    "    You should set `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    located at ~/.keras/keras.json.\n",
    "    Note that the default input image size for this model is 299x299.\n",
    "    # Arguments\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "    if K.backend() != 'tensorflow':\n",
    "        raise Exception('The Xception model is only available with '\n",
    "                        'the TensorFlow backend.')\n",
    "    if K.image_dim_ordering() != 'tf':\n",
    "        warnings.warn('The Xception model is only available for the '\n",
    "                      'input dimension ordering \"tf\" '\n",
    "                      '(width, height, channels). '\n",
    "                      'However your settings specify the default '\n",
    "                      'dimension ordering \"th\" (channels, width, height). '\n",
    "                      'You should set `image_dim_ordering=\"tf\"` in your Keras '\n",
    "                      'config located at ~/.keras/keras.json. '\n",
    "                      'The model being returned right now will expect inputs '\n",
    "                      'to follow the \"tf\" dimension ordering.')\n",
    "        K.set_image_dim_ordering('tf')\n",
    "        old_dim_ordering = 'th'\n",
    "    else:\n",
    "        old_dim_ordering = None\n",
    "\n",
    "    # Determine proper input shape\n",
    "    if include_top:\n",
    "        input_shape = (299, 299, 3)\n",
    "    else:\n",
    "        input_shape = (None, None, 3)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    #x = Conv2D(32, 3, 3, subsample=(2, 2), bias=False, name='block1_conv1')(img_input)\n",
    "    x = Conv2D(32, (3, 3), name=\"block1_conv1\", strides=(2, 2), use_bias=False)(img_input)\n",
    "    x = BatchNormalization(name='block1_conv1_bn')(x)\n",
    "    x = Activation('relu', name='block1_conv1_act')(x)\n",
    "    #x = Conv2D(64, 3, 3, bias=False, name='block1_conv2')(x)\n",
    "    x = Conv2D(64, (3, 3), name=\"block1_conv2\", use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block1_conv2_bn')(x)\n",
    "    x = Activation('relu', name='block1_conv2_act')(x)\n",
    "\n",
    "    #residual = Conv2D(128, 1, 1, subsample=(2, 2), border_mode='same', bias=False)(x)\n",
    "    residual = Conv2D(128, (1, 1), strides=(2, 2), padding=\"same\", use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    #x = SeparableConv2D(128, 3, 3, border_mode='same', bias=False, name='block2_sepconv1')(x)\n",
    "    x = SeparableConv2D(128, (3, 3), name=\"block2_sepconv1\", padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block2_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block2_sepconv2_act')(x)\n",
    "    #x = SeparableConv2D(128, 3, 3, border_mode='same', bias=False, name='block2_sepconv2')(x)\n",
    "    x = SeparableConv2D(128, (3, 3), name=\"block2_sepconv2\", padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block2_sepconv2_bn')(x)\n",
    "\n",
    "    #x = MaxPooling2D((3, 3), strides=(2, 2), border_mode='same', name='block2_pool')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name=\"block2_pool\", padding=\"same\")(x)\n",
    "    #x = merge([x, residual], mode='sum')\n",
    "    x = add([x, residual])\n",
    "\n",
    "    #residual = Conv2D(256, 1, 1, subsample=(2, 2), border_mode='same', bias=False)(x)\n",
    "    residual = Conv2D(256, (1, 1), strides=(2, 2), padding=\"same\", use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = Activation('relu', name='block3_sepconv1_act')(x)\n",
    "    #x = SeparableConv2D(256, 3, 3, border_mode='same', bias=False, name='block3_sepconv1')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), name=\"block3_sepconv1\", padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block3_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block3_sepconv2_act')(x)\n",
    "    #x = SeparableConv2D(256, 3, 3, border_mode='same', bias=False, name='block3_sepconv2')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), name=\"block3_sepconv2\", padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block3_sepconv2_bn')(x)\n",
    "\n",
    "    #x = MaxPooling2D((3, 3), strides=(2, 2), border_mode='same', name='block3_pool')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name=\"block3_pool\", padding=\"same\")(x)\n",
    "    #x = merge([x, residual], mode='sum')\n",
    "    x = add([x, residual])\n",
    "\n",
    "    #residual = Conv2D(728, 1, 1, subsample=(2, 2), border_mode='same', bias=False)(x)\n",
    "    residual = Conv2D(728, (1, 1), strides=(2, 2), padding=\"same\", use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = Activation('relu', name='block4_sepconv1_act')(x)\n",
    "    #x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name='block4_sepconv1')(x)\n",
    "    x = SeparableConv2D(728, (3, 3), name=\"block4_sepconv1\", padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block4_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block4_sepconv2_act')(x)\n",
    "    #x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name='block4_sepconv2')(x)\n",
    "    x = SeparableConv2D(728, (3, 3), name=\"block4_sepconv2\", padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block4_sepconv2_bn')(x)\n",
    "\n",
    "    #x = MaxPooling2D((3, 3), strides=(2, 2), border_mode='same', name='block4_pool')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name=\"block4_pool\", padding=\"same\")(x)\n",
    "    #x = merge([x, residual], mode='sum')\n",
    "    x = add([x, residual])\n",
    "\n",
    "    for i in range(8):\n",
    "        residual = x\n",
    "        prefix = 'block' + str(i + 5)\n",
    "\n",
    "        x = Activation('relu', name=prefix + '_sepconv1_act')(x)\n",
    "        #x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name=prefix + '_sepconv1')(x)\n",
    "        x = SeparableConv2D(728, (3, 3), name=prefix + '_sepconv1', padding=\"same\", use_bias=False)(x)\n",
    "        x = BatchNormalization(name=prefix + '_sepconv1_bn')(x)\n",
    "        x = Activation('relu', name=prefix + '_sepconv2_act')(x)\n",
    "        #x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name=prefix + '_sepconv2')(x)\n",
    "        x = SeparableConv2D(728, (3, 3), name=prefix + '_sepconv2', padding=\"same\", use_bias=False)(x)\n",
    "        x = BatchNormalization(name=prefix + '_sepconv2_bn')(x)\n",
    "        x = Activation('relu', name=prefix + '_sepconv3_act')(x)\n",
    "        #x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name=prefix + '_sepconv3')(x)\n",
    "        x = SeparableConv2D(728, (3, 3), name=prefix + '_sepconv3', padding=\"same\", use_bias=False)(x)\n",
    "        x = BatchNormalization(name=prefix + '_sepconv3_bn')(x)\n",
    "\n",
    "        #x = merge([x, residual], mode='sum')\n",
    "        x = add([x, residual])\n",
    "\n",
    "    #residual = Conv2D(1024, 1, 1, subsample=(2, 2), border_mode='same', bias=False)(x)\n",
    "    residual = Conv2D(1024, (1, 1), strides=(2, 2), padding=\"same\", use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = Activation('relu', name='block13_sepconv1_act')(x)\n",
    "    #x = SeparableConv2D(728, 3, 3, border_mode='same', bias=False, name='block13_sepconv1')(x)\n",
    "    x = SeparableConv2D(728, (3, 3), name=\"block13_sepconv1\", padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block13_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block13_sepconv2_act')(x)\n",
    "    #x = SeparableConv2D(1024, 3, 3, border_mode='same', bias=False, name='block13_sepconv2')(x)\n",
    "    x = SeparableConv2D(1024, (3, 3), name=\"block13_sepconv2\", padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block13_sepconv2_bn')(x)\n",
    "\n",
    "    #x = MaxPooling2D((3, 3), strides=(2, 2), border_mode='same', name='block13_pool')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name=\"block13_pool\", padding=\"same\")(x)\n",
    "    #x = merge([x, residual], mode='sum')\n",
    "    x = add([x, residual])\n",
    "\n",
    "    #x = SeparableConv2D(1536, 3, 3, border_mode='same', bias=False, name='block14_sepconv1')(x)\n",
    "    x = SeparableConv2D(1536, (3, 3), name=\"block14_sepconv1\", padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block14_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block14_sepconv1_act')(x)\n",
    "\n",
    "    #x = SeparableConv2D(2048, 3, 3, border_mode='same', bias=False, name='block14_sepconv2')(x)\n",
    "    x = SeparableConv2D(2048, (3, 3), name=\"block14_sepconv2\", padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block14_sepconv2_bn')(x)\n",
    "    x = Activation('relu', name='block14_sepconv2_act')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(img_input, x)\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = TF_WEIGHTS_PATH #get_file('xception_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    #TF_WEIGHTS_PATH,\n",
    "                                    #cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = TF_WEIGHTS_PATH_NO_TOP #get_file('xception_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    #TF_WEIGHTS_PATH_NO_TOP,\n",
    "                                    #cache_subdir='models')\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    if old_dim_ordering:\n",
    "        K.set_image_dim_ordering(old_dim_ordering)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(include_top=False, weights='imagenet', input_tensor=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning\n",
    "# Add new last layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(nb_classes, activation='relu')(x) #new FC layer, random init\n",
    "predictions = Dense(nb_classes, activation='softmax')(x) #new softmax layer\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all layers of the based model that is already pre-trained\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4032 images belonging to 2 classes.\n",
      "Found 1372 images belonging to 2 classes.\n",
      "4032\n",
      "1372\n"
     ]
    }
   ],
   "source": [
    "# Read Data and Augment it: Make sure to select augmentations that are appropriate to your images\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                       rotation_range=transformation_ratio,\n",
    "                                       shear_range=transformation_ratio,\n",
    "                                       zoom_range=transformation_ratio,\n",
    "                                       cval=transformation_ratio,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('data/train/',\n",
    "                                                        target_size=(img_width, img_height),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        shuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory('data/validation/',\n",
    "                                                                  target_size=(img_width, img_height),\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='categorical',\n",
    "                                                                  shuffle=True)\n",
    "filenames_train = train_generator.filenames\n",
    "nb_samples_train = len(filenames_train)\n",
    "print(nb_samples_train)\n",
    "filenames_valid = validation_generator.filenames\n",
    "nb_samples_valid = len(filenames_valid)\n",
    "print(nb_samples_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n",
    "                  loss='categorical_crossentropy',  # categorical_crossentropy if multi-class classifier\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights of best training epoch: monitor either val_loss or val_acc\n",
    "top_weights_path = os.path.join(os.path.abspath('data'), 'top_model_weights.h5')\n",
    "callbacks_list = [\n",
    "        ModelCheckpoint(top_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
    "        EarlyStopping(monitor='val_acc', patience=5, verbose=0)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9c0911e9a05e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m                         \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                         callbacks = callbacks_list)\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlegacy_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1874\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1875\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1876\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1878\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1620\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1621\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1622\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2073\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2074\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 2075\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   2076\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train Simple CNN\n",
    "history1 = model.fit_generator(train_generator,\n",
    "                        steps_per_epoch = int((100 / batch_size) + 1),\n",
    "                        epochs = 2,\n",
    "                        validation_data = validation_generator,\n",
    "                        validation_steps = int((20 / batch_size) + 1),\n",
    "                        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting to Fine Tune Model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting to Fine Tune Model\\n\")\n",
    "# we re-load model weights to ensure the best epoch is selected and not the last one.\n",
    "model.load_weights(top_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model will be re-trained based on the new data\n",
    "# based_model_last_block_layer_number points to the layer in your model you want to train.\n",
    "for layer in model.layers[:based_model_last_block_layer_number]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[based_model_last_block_layer_number:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(optimizer='nadam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights of best training epoch: monitor either val_loss or val_acc\n",
    "final_weights_path = os.path.join(os.path.abspath('data/model'), 'model_weights.h5')\n",
    "callbacks_list = [\n",
    "        ModelCheckpoint(final_weights_path, monitor='val_acc', verbose=1, save_best_only=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tune the model\n",
    "history2 = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = int((nb_samples_train / batch_size) + 1),\n",
    "                    epochs = 1,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = int((nb_samples_valid / batch_size) + 1),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(os.path.abspath('data/model'), 'model.json'), 'w') as json_file:\n",
    "        json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "  acc = history.history['acc']\n",
    "  val_acc = history.history['val_acc']\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "  epochs = range(len(acc))\n",
    "\n",
    "  plt.plot(epochs, acc, 'r.')\n",
    "  plt.plot(epochs, val_acc, 'r')\n",
    "  plt.title('Training and validation accuracy')\n",
    "\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, loss, 'r.')\n",
    "  plt.plot(epochs, val_loss, 'r-')\n",
    "  plt.title('Training and validation loss')\n",
    "  plt.show()\n",
    "\n",
    "#plot_training(history1)\n",
    "#plot_training(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('data/model/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(final_weights_path)\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'data/test/',\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle = False)\n",
    "\n",
    "filenames_test = test_generator.filenames\n",
    "nb_samples_test = len(filenames_test)\n",
    "\n",
    "scores = loaded_model.evaluate_generator(test_generator,steps = int((nb_samples_test / batch_size) + 1)) #1514 testing images\n",
    "print(\"Accuracy = \", scores[1])\n",
    "\n",
    "#predict = loaded_model.predict_generator(test_generator,steps = int((nb_samples_test / batch_size) + 1))\n",
    "#predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
